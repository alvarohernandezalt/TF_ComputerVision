{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a binary classifier to detect smiles"
      ],
      "metadata": {
        "id": "M9NmVXJONpxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In its most basic form, image classification consists of discerning between two classes, or signaling the presence or absence of some trait. In this recipe, we'll implement a binary classifier that tells us wether a person in a photo is smiling."
      ],
      "metadata": {
        "id": "tY8SZxFQN9Xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are working inside Colab we need to install wget to pass the SMILEs dataset from GDrive to Colab"
      ],
      "metadata": {
        "id": "Kdvd_oy-VVCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qNT968JVMNv",
        "outputId": "3a6155bd-96df-4697-fa2f-f0ffdf6000e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=53bcfaf5101f2c1331b7bf7b79195f83a92bd013a80d2e01e47d5988e741cb95\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all necessary packages\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import wget\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import *"
      ],
      "metadata": {
        "id": "bShpoBDpN-xA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to load the images and labels from a list of file paths\n",
        "\n",
        "def load_images_and_labels(image_paths):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for image_path in image_paths:\n",
        "    image = load_img(image_path, target_size=(32,32),\n",
        "                     color_mode='grayscale')\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    label = image_path.split(os.path.sep)[-2]\n",
        "    label = 'positive' in label\n",
        "    label = float(label)\n",
        "\n",
        "    images.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "  return np.array(images), np.array(labels)\n"
      ],
      "metadata": {
        "id": "xDMqiM8WVKbg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build the neural network.\n",
        "# This model's structure is based on LeNet\n",
        "\n",
        "def build_network():\n",
        "  input_layer = Input(shape=(32,32,1))\n",
        "  x = Conv2D(filters=20,\n",
        "             kernel_size=(5,5),\n",
        "             padding='same',\n",
        "             strides=(1,1))(input_layer)\n",
        "  x = ELU()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2),\n",
        "                   strides=(2,2))(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "\n",
        "  x = Conv2D(filters=50,\n",
        "             kernel_size=(5,5),\n",
        "             padding='same',\n",
        "             strides=(1,1))(x)\n",
        "  x = ELU()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2),\n",
        "                   strides=(2,2))(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(units=500)(x)\n",
        "  x = ELU()(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "\n",
        "  output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs=input_layer, outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "RFUCj-i9WcQu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cw-eHYcMZF5L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}